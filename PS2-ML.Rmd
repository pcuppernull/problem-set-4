---
title: "Problem Set 2"
author: "Pete Cuppernull"
date: "1/30/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###Load Packages and Clean
```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(modelr)
library(broom) 
library(rsample) 
library(patchwork)
library(corrplot)
library(ISLR)
library(caret)
library(rcfss)
library(yardstick)
library(stargazer)
biden <- read_csv("/Users/petecuppernull/Dropbox/UChicago/2019-20/Winter/Machine Learning/Repos/Problem-Set-2-ML/nes2008.csv")

biden <- biden %>%
  select(biden, female, age, educ, dem, rep) %>%
  na.omit()

```

# 1. Estimate MSE
```{r}
biden_traditional <- glm(biden ~ .,
                          data = biden)
biden_mse <- modelr::mse(biden_traditional, biden)

stargazer(biden_traditional, type = "text")

```

The MSE of the traditional model is `r biden_mse`. The simple linear model shows that partisanship explains much of an individual's feelings towards Biden, as evidenced by the relatively large and statistically significant coefficients on the democrat and republican variables. An individual's gender also can help explain feelings towards Biden.  Somewhat surprisingly, education level and age seem to have the least bearing on one’s feelings towards Biden — this might indicate that despite age, an individual’s party identification explains much of their political preferences.

#2. Simple Holdout Validation
```{r}
##Split data
set.seed(1414)
split <- initial_split(biden, prop = .5) 
biden_train <- training(split)
biden_test <- testing(split)

#Fit model w/ training data
biden_train_ho <- lm(biden ~ .,
                          data = biden_train)

summary(biden_train_ho)

#Calculate MSE
biden_mse_test <- modelr::mse(biden_train_ho, biden_test)

```
The MSE of the test set of the holdout model is `r biden_mse_test`. Considering that the MSE of the traditional model is `r biden_mse`, the simple holdout appraoch provides a more accurate learner. This suggests that we may have been overfitting the data in the traditional model, and actually building a model on fewer observations in the holdout approach results in a more accurate learner.

#3. Bootstrap
```{r, message=FALSE}
mean_biden <- function(splits) {
  x <- analysis(splits)
  mean(x$biden)
}

##function for mse
biden_mse_boot <- function(split_data){
  
biden_train_ho <- lm(biden ~ .,
                          data = split_data)
biden_mse_train <- modelr::mse(biden_train_ho, split_data)
biden_mse_train
}


biden_bootstrap <- biden %>%
  bootstraps(1000) %>%
  mutate(mean = map_dbl(splits, mean_biden)) %>%
  mutate(mse_boot = map_dbl(splits, biden_mse_boot))

#Means
ggplot(biden_bootstrap) +
  geom_histogram(aes(mean)) +
  geom_vline(xintercept = mean(biden_bootstrap$mean)) +
  labs(x = "Mean",
       y = "Frequency",
       title = "Distribution of Means",
       subtitle = "1000 Bootstraps")

#MSE
ggplot(biden_bootstrap) +
  geom_histogram(aes(mse_boot)) +
  geom_vline(xintercept = mean(biden_bootstrap$mse_boot)) +
  labs(x = "MSE",
       y = "Frequency",
       title = "Distribution of MSE",
       subtitle = "1000 Bootstraps")
```
The mean of the sample means is `r mean(biden_bootstrap$mean)` and the mean of the MSEs is `r mean(biden_bootstrap$mse_boot)`. We can observe that the individual values of both appear to be drawn from a normal distribution, which we would expect. The mean of the bootstrapped means and MSEs also approximately converge on the true mean (`r mean(biden$biden)`) and MSE (`r biden_mse`) of the original sample.

## Question 4. Comparison

```{r}
stargazer(biden_traditional, type = "text")

model_coef <- function(splits, ...) {
  mod <- lm(..., data = analysis(splits))
  tidy(mod)
}

biden_bootstrap4 <- biden %>%
  as_tibble()%>%
  bootstraps(1000)%>%
  mutate(coef = map(splits, model_coef, as.formula(biden ~ .))) 

bootstrap_coefs <- biden_bootstrap4 %>%
  unnest(coef) %>%
  group_by(term) %>% 
  summarize(.estimate = mean(estimate),
            .se = sd(estimate, na.rm = TRUE))

summary(biden_traditional)$coefficients

```

Considering the outputs of our first model and our bootstrapped model, we can see that partisanship remains the strongest indicator of feelings towards Biden in both models. We also observe similar coeffiecients for the gender, age, and education variables. However, the standard errors in the bootstrapped model are slightly larger than in the original model, as we would expect — the bootstrapped model does not assume a strict functional form, and if we had reserved confidence in this assumption when analyzing this data, the bootstrapped model would be a more appropriate modeling choice.
